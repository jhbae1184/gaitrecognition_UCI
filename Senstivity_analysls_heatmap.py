import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns  # íˆíŠ¸ë§µ ì‹œê°í™”ìš©
from tqdm import tqdm  # ì§„í–‰ë¥  í‘œì‹œë°”

# --- Scikit-learn ---
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# --- Signal Processing ---
from scipy.signal import butter, filtfilt

# =============================================================================
# 1. ê¸°ë³¸ í•¨ìˆ˜ ì •ì˜ (í•„í„°, ìœˆë„ìš°, íŠ¹ì§• ì¶”ì¶œ)
# =============================================================================

def butter_bandpass_filter(data, lowcut, highcut, fs, order=4):
    nyq = 0.5 * fs
    # ìœ íš¨ì„± ê²€ì‚¬: Lowê°€ Highë³´ë‹¤ í¬ê±°ë‚˜ ê°™ìœ¼ë©´ í•„í„° ìƒì„± ë¶ˆê°€ -> ì›ë³¸ ë°˜í™˜ í˜¹ì€ ì—ëŸ¬ ì²˜ë¦¬
    if lowcut >= highcut:
        return np.zeros_like(data) 
    
    low = lowcut / nyq
    high = highcut / nyq
    
    # ì•ˆì „ ì¥ì¹˜: Nyquist ì£¼íŒŒìˆ˜(fs/2)ë¥¼ ë„˜ì§€ ì•Šë„ë¡
    if high >= 1.0: high = 0.99
        
    b, a = butter(order, [low, high], btype='band')
    axis = 0 if data.ndim > 1 else -1
    y = filtfilt(b, a, data, axis=axis)
    return y

def sliding_window(data, window_size, step_size):
    num_windows = (len(data) - window_size) // step_size + 1
    windows = []
    for i in range(num_windows):
        start = i * step_size
        end = start + window_size
        windows.append(data[start:end])
    return np.array(windows)

def extract_features(window):
    mav = np.mean(np.abs(window), axis=0)
    waveform_length = np.sum(np.abs(np.diff(window, axis=0)), axis=0)
    # features = np.concatenate([np.atleast_1d(mav), np.atleast_1d(waveform_length)])
    features = np.atleast_1d(waveform_length)
    return features

# =============================================================================
# 2. ìµœì í™”ëœ ë°ì´í„° ë¡œë” (Raw Data Caching)
# =============================================================================

def load_raw_data_to_memory(path_normal, path_abnormal):
    """
    CSV íŒŒì¼ì„ ë§¤ë²ˆ ì½ì§€ ì•Šê³ , Raw Signal ìƒíƒœë¡œ ë©”ëª¨ë¦¬ì— ì €ì¥í•´ë‘ .
    ë°˜í™˜: [{'signal': numpy_array, 'label': int}, ...]
    """
    raw_dataset = []
    paths = [(path_normal, 0), (path_abnormal, 1)]
    
    print("ğŸ“‚ Raw ë°ì´í„° ë©”ëª¨ë¦¬ ë¡œë”© ì¤‘ (ì†ë„ ìµœì í™”)...")
    
    for base_path, label_type in paths:
        if not os.path.exists(base_path): continue
        file_list = os.listdir(base_path)
        
        # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ íŒŒì¼ ìˆ˜ ì œí•œì´ í•„ìš”í•˜ë©´ ìŠ¬ë¼ì´ì‹± ì‚¬ìš© (ì˜ˆ: file_list[:20])
        for filename in file_list:
            if not filename.lower().endswith('.csv'): continue
            
            try:
                df = pd.read_csv(os.path.join(base_path, filename))
                raw_signal = df.select_dtypes(include=[np.number]).to_numpy()
                
                # ì‹ í˜¸ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ íŒ¨ìŠ¤
                if raw_signal.shape[0] < 200: continue 

                raw_dataset.append({
                    'signal': raw_signal,
                    'label': label_type,
                    'filename': filename
                })
            except Exception:
                continue
                
    print(f"âœ… ì´ {len(raw_dataset)}ê°œì˜ íŒŒì¼ì´ ë©”ëª¨ë¦¬ì— ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    return raw_dataset

# =============================================================================
# 3. ì‹¤í—˜ íŒŒì´í”„ë¼ì¸ (íŒŒë¼ë¯¸í„° -> ì •í™•ë„ ë°˜í™˜)
# =============================================================================

def evaluate_filter_params(raw_dataset, low, high, fs=1000, order=4, window_size=200, step_size=100):
    all_X = []
    all_y = []
    
    expected_dim = None
    
    # ë©”ëª¨ë¦¬ì— ìˆëŠ” Raw ë°ì´í„° ìˆœíšŒ
    for item in raw_dataset:
        raw_sig = item['signal']
        label = item['label']
        
        # 1. í•„í„°ë§
        filtered_sig = butter_bandpass_filter(raw_sig, low, high, fs, order)
        # í•„í„° ì˜¤ë¥˜(zeros)ì¸ ê²½ìš° ê±´ë„ˆëœ€
        if np.all(filtered_sig == 0): continue

        # 2. ìœˆë„ìš°
        windows = sliding_window(filtered_sig, window_size, step_size)
        if len(windows) == 0: continue
        
        # 3. íŠ¹ì§• ì¶”ì¶œ
        temp_feats = []
        skip = False
        for w in windows:
            feat = extract_features(w)
            
            if expected_dim is None: expected_dim = feat.shape[0]
            if feat.shape[0] != expected_dim:
                skip = True
                break
            temp_feats.append(feat)
            
        if not skip:
            all_X.extend(temp_feats)
            all_y.extend([label] * len(temp_feats))
            
    if len(all_X) == 0: return 0.0
    
    X = np.array(all_X)
    y = np.array(all_y)
    
    # 4. SVM í•™ìŠµ ë° í‰ê°€
    # ë°ì´í„°ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ì†ë„ë¥¼ ìœ„í•´ ì¼ë¶€ë§Œ ìƒ˜í”Œë§ ê°€ëŠ¥ (í˜„ì¬ëŠ” ì „ì²´ ì‚¬ìš©)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)
    
    svm = SVC(kernel='rbf', gamma='scale', random_state=42)
    svm.fit(X_train, y_train)
    
    return accuracy_score(y_test, svm.predict(X_test))

# =============================================================================
# 4. ë©”ì¸ ì‹¤í–‰ (Sensitivity Grid Search)
# =============================================================================

def main():
    # --- ê²½ë¡œ ì„¤ì • ---
    PATH_NORMAL   = r"./Gait1-UCI/normal/"
    PATH_ABNORMAL = r"./Gait1-UCI/Abnormal/"

    # 1. Raw ë°ì´í„° ë¡œë“œ (1íšŒë§Œ ìˆ˜í–‰)
    raw_data = load_raw_data_to_memory(PATH_NORMAL, PATH_ABNORMAL)
    if not raw_data:
        print("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨.")
        return

    # --- Grid Search ë²”ìœ„ ì„¤ì • ---
    # Low Cutoff: 10Hz ~ 100Hz (20Hz ê°„ê²©)
    low_range = [10, 30, 50, 70, 90] 
    # High Cutoff: 150Hz ~ 450Hz (50Hz ê°„ê²©)
    high_range = [150, 200, 250, 300, 350]
    
    # ê²°ê³¼ë¥¼ ì €ì¥í•  í–‰ë ¬ (í–‰: High, ì—´: Low) - Heatmap êµ¬ì¡°ìƒ ì´ê²Œ ë³´ê¸° í¸í•¨
    accuracy_grid = np.zeros((len(high_range), len(low_range)))
    
    print(f"\nğŸ” Sensitivity Analysis ì‹œì‘ (ì´ {len(low_range) * len(high_range)}íšŒ ì‹¤í—˜)...")
    
    # Grid Search Loop
    # tqdmì„ ì‚¬ìš©í•˜ì—¬ ì§„í–‰ë¥  í‘œì‹œ
    total_iterations = len(low_range) * len(high_range)
    pbar = tqdm(total=total_iterations)

    for i, h_val in enumerate(high_range):
        for j, l_val in enumerate(low_range):
            
            if l_val >= h_val:
                acc = 0.0 # ë¶ˆê°€ëŠ¥í•œ í•„í„° ì„¤ì •
            else:
                acc = evaluate_filter_params(
                    raw_data, low=l_val, high=h_val, fs=1000, 
                    window_size=200, step_size=100
                )
            
            accuracy_grid[i, j] = acc
            pbar.update(1)
            # pbar.set_description(f"L:{l_val}-H:{h_val} Acc:{acc:.3f}")

    pbar.close()

    # =============================================================================
    # 5. ê²°ê³¼ ì‹œê°í™” (Heatmap)
    # =============================================================================
    
    plt.figure(figsize=(10, 8))
    
    # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ Seabornì— ì „ë‹¬ (ì¶• ë¼ë²¨ë§ ìš©ì´)
    df_heatmap = pd.DataFrame(accuracy_grid, index=high_range, columns=low_range)
    
    # Heatmap ê·¸ë¦¬ê¸°
    sns.heatmap(df_heatmap, annot=True, fmt=".3f", cmap="RdYlGn", 
                linewidths=.5, cbar_kws={'label': 'Classification Accuracy'})
    
    plt.title('Sensitivity Analysis: SVM Accuracy vs Filter Parameters', fontsize=14)
    plt.xlabel('Low Cutoff Frequency (Hz)', fontsize=12)
    plt.ylabel('High Cutoff Frequency (Hz)', fontsize=12)
    
    # Yì¶• ë°©í–¥ ì •ë ¬ (ë†’ì€ ì£¼íŒŒìˆ˜ê°€ ìœ„ë¡œ ê°€ê²Œ)
    plt.gca().invert_yaxis() 
    
    plt.tight_layout()
    plt.savefig("sensitivity_heatmap.png")
    print("\nâœ… ë¶„ì„ ì™„ë£Œ! 'sensitivity_heatmap.png' íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    # plt.show()

if __name__ == "__main__":
    main()